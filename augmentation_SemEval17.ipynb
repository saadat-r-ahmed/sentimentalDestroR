{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREAETING THE AUGMENTED DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r venv_txtatck\n",
    "!python3.7 -m venv venv_txtatck\n",
    "!pip install textattack -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /home/maxwell/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from textattack.augmentation.recipes import EasyDataAugmenter\n",
    "easyAugmenter = EasyDataAugmenter(pct_words_to_swap=0.5, transformations_per_example=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    'Sentiment_Dataset/SemEval17/Clean/semeval.csv', \n",
    "    encoding = 'utf-8'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['augmented'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>text</th>\n",
       "      <th>augmented</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEU</td>\n",
       "      <td>Picturehouse's, Pink Floyd's, 'Roger Waters: T...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEU</td>\n",
       "      <td>Order Go Set a Watchman in store or through ou...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEG</td>\n",
       "      <td>If these runway renovations at the airport pre...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEU</td>\n",
       "      <td>If you could ask an onstage interview question...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POS</td>\n",
       "      <td>A portion of book sales from our Harper Lee/Go...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20627</th>\n",
       "      <td>NEU</td>\n",
       "      <td>@ShaquilleHoNeal from what I think you're aski...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20628</th>\n",
       "      <td>POS</td>\n",
       "      <td>Iran ranks 1st in liver surgeries, Allah bless...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20629</th>\n",
       "      <td>NEU</td>\n",
       "      <td>Hours before he arrived in Saudi Arabia on Tue...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20630</th>\n",
       "      <td>NEG</td>\n",
       "      <td>@VanityFair  Alex Kim Kardashian worth how to ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20631</th>\n",
       "      <td>NEU</td>\n",
       "      <td>I guess even Pandora knows Justin Bieber is a ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20632 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      polarity                                               text  augmented\n",
       "0          NEU  Picturehouse's, Pink Floyd's, 'Roger Waters: T...        NaN\n",
       "1          NEU  Order Go Set a Watchman in store or through ou...        NaN\n",
       "2          NEG  If these runway renovations at the airport pre...        NaN\n",
       "3          NEU  If you could ask an onstage interview question...        NaN\n",
       "4          POS  A portion of book sales from our Harper Lee/Go...        NaN\n",
       "...        ...                                                ...        ...\n",
       "20627      NEU  @ShaquilleHoNeal from what I think you're aski...        NaN\n",
       "20628      POS  Iran ranks 1st in liver surgeries, Allah bless...        NaN\n",
       "20629      NEU  Hours before he arrived in Saudi Arabia on Tue...        NaN\n",
       "20630      NEG  @VanityFair  Alex Kim Kardashian worth how to ...        NaN\n",
       "20631      NEU  I guess even Pandora knows Justin Bieber is a ...        NaN\n",
       "\n",
       "[20632 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20632 [00:00<?, ?it/s]/tmp/ipykernel_36943/4289361308.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"augmented\"][i] = easyAugmenter.augment(data[\"text\"][i])[0]\n",
      "100%|██████████| 20632/20632 [34:10<00:00, 10.06it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for i in tqdm(range(len(data))):\n",
    "    data[\"augmented\"][i] = easyAugmenter.augment(data[\"text\"][i])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>text</th>\n",
       "      <th>augmented</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEU</td>\n",
       "      <td>Picturehouse's, Pink Floyd's, 'Roger Waters: T...</td>\n",
       "      <td>Picturehouse's,, 'Roger: The - opening 29 Sept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEU</td>\n",
       "      <td>Order Go Set a Watchman in store or through ou...</td>\n",
       "      <td>tell proceed countersink a watchman in stock o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEG</td>\n",
       "      <td>If these runway renovations at the airport pre...</td>\n",
       "      <td>If these rails restoration at the aerodrome fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEU</td>\n",
       "      <td>If you could ask an onstage interview question...</td>\n",
       "      <td>If ask an onstage Miss USA tomorrow, it?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POS</td>\n",
       "      <td>A portion of book sales from our Harper Lee/Go...</td>\n",
       "      <td>ampere dowry of Koran sales from our Harper le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20627</th>\n",
       "      <td>NEU</td>\n",
       "      <td>@ShaquilleHoNeal from what I think you're aski...</td>\n",
       "      <td>@asking what from in Future no ShaquilleHoNeal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20628</th>\n",
       "      <td>POS</td>\n",
       "      <td>Iran ranks 1st in liver surgeries, Allah bless...</td>\n",
       "      <td>Iran outrank ranks 1st first in liver surgerie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20629</th>\n",
       "      <td>NEU</td>\n",
       "      <td>Hours before he arrived in Saudi Arabia on Tue...</td>\n",
       "      <td>Hours Tuesday he Arabia mercilessly Syria's in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20630</th>\n",
       "      <td>NEG</td>\n",
       "      <td>@VanityFair  Alex Kim Kardashian worth how to ...</td>\n",
       "      <td>@VanityFair  Alex Kim Kardashian Worth how to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20631</th>\n",
       "      <td>NEU</td>\n",
       "      <td>I guess even Pandora knows Justin Bieber is a ...</td>\n",
       "      <td>ace estimate still Pandora recognize Justin Bi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20632 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      polarity                                               text  \\\n",
       "0          NEU  Picturehouse's, Pink Floyd's, 'Roger Waters: T...   \n",
       "1          NEU  Order Go Set a Watchman in store or through ou...   \n",
       "2          NEG  If these runway renovations at the airport pre...   \n",
       "3          NEU  If you could ask an onstage interview question...   \n",
       "4          POS  A portion of book sales from our Harper Lee/Go...   \n",
       "...        ...                                                ...   \n",
       "20627      NEU  @ShaquilleHoNeal from what I think you're aski...   \n",
       "20628      POS  Iran ranks 1st in liver surgeries, Allah bless...   \n",
       "20629      NEU  Hours before he arrived in Saudi Arabia on Tue...   \n",
       "20630      NEG  @VanityFair  Alex Kim Kardashian worth how to ...   \n",
       "20631      NEU  I guess even Pandora knows Justin Bieber is a ...   \n",
       "\n",
       "                                               augmented  \n",
       "0      Picturehouse's,, 'Roger: The - opening 29 Sept...  \n",
       "1      tell proceed countersink a watchman in stock o...  \n",
       "2      If these rails restoration at the aerodrome fo...  \n",
       "3               If ask an onstage Miss USA tomorrow, it?  \n",
       "4      ampere dowry of Koran sales from our Harper le...  \n",
       "...                                                  ...  \n",
       "20627  @asking what from in Future no ShaquilleHoNeal...  \n",
       "20628  Iran outrank ranks 1st first in liver surgerie...  \n",
       "20629  Hours Tuesday he Arabia mercilessly Syria's in...  \n",
       "20630  @VanityFair  Alex Kim Kardashian Worth how to ...  \n",
       "20631  ace estimate still Pandora recognize Justin Bi...  \n",
       "\n",
       "[20632 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir Sentiment_Dataset/SemEval17/Augmented\n",
    "data.to_csv(\"./Sentiment_Dataset/SemEval17/Augmented/augmented_SemEval17.csv\",encoding='utf-8')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATING THE PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pysentimiento\n",
      "  Downloading pysentimiento-0.6.7-py3-none-any.whl (38 kB)\n",
      "Collecting torch<2.0.0,>=1.13.1\n",
      "  Using cached torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
      "Requirement already satisfied: transformers>=4.13.0 in /home/maxwell/anaconda3/lib/python3.10/site-packages (from pysentimiento) (4.24.0)\n",
      "Collecting spacy<4.0.0,>=3.5.0\n",
      "  Downloading spacy-3.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting emoji<2.0.0,>=1.6.1\n",
      "  Using cached emoji-1.7.0.tar.gz (175 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: datasets>=1.13.3 in /home/maxwell/anaconda3/lib/python3.10/site-packages (from pysentimiento) (2.4.0)\n",
      "Requirement already satisfied: aiohttp in /home/maxwell/anaconda3/lib/python3.10/site-packages (from datasets>=1.13.3->pysentimiento) (3.8.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/maxwell/anaconda3/lib/python3.10/site-packages (from datasets>=1.13.3->pysentimiento) (1.23.5)\n",
      "Requirement already satisfied: responses<0.19 in /home/maxwell/anaconda3/lib/python3.10/site-packages (from datasets>=1.13.3->pysentimiento) (0.18.0)\n",
      "Requirement already satisfied: dill<0.3.6 in /home/maxwell/anaconda3/lib/python3.10/site-packages (from datasets>=1.13.3->pysentimiento) (0.3.5.1)\n",
      "Requirement already satisfied: packaging in /home/maxwell/anaconda3/lib/python3.10/site-packages (from datasets>=1.13.3->pysentimiento) (22.0)\n",
      "Requirement already satisfied: multiprocess in /home/maxwell/anaconda3/lib/python3.10/site-packages (from datasets>=1.13.3->pysentimiento) (0.70.13)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/maxwell/.local/lib/python3.10/site-packages (from datasets>=1.13.3->pysentimiento) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /home/maxwell/anaconda3/lib/python3.10/site-packages (from datasets>=1.13.3->pysentimiento) (3.2.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /home/maxwell/anaconda3/lib/python3.10/site-packages (from datasets>=1.13.3->pysentimiento) (0.10.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/maxwell/anaconda3/lib/python3.10/site-packages (from datasets>=1.13.3->pysentimiento) (2.28.1)\n",
      "Requirement already satisfied: pandas in /home/maxwell/anaconda3/lib/python3.10/site-packages (from datasets>=1.13.3->pysentimiento) (1.5.3)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/maxwell/anaconda3/lib/python3.10/site-packages (from datasets>=1.13.3->pysentimiento) (2022.11.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /home/maxwell/anaconda3/lib/python3.10/site-packages (from datasets>=1.13.3->pysentimiento) (11.0.0)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Using cached catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4\n",
      "  Using cached pydantic-1.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Using cached srsly-2.4.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (492 kB)\n",
      "Collecting pathy>=0.10.0\n",
      "  Using cached pathy-0.10.1-py3-none-any.whl (48 kB)\n",
      "Requirement already satisfied: jinja2 in /home/maxwell/anaconda3/lib/python3.10/site-packages (from spacy<4.0.0,>=3.5.0->pysentimiento) (3.1.2)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Using cached murmurhash-1.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Collecting typer<0.8.0,>=0.3.0\n",
      "  Using cached typer-0.7.0-py3-none-any.whl (38 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Using cached preshed-3.0.8-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Using cached wasabi-1.1.1-py3-none-any.whl (27 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Using cached langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Using cached spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Using cached cymem-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34 kB)\n",
      "Collecting thinc<8.2.0,>=8.1.8\n",
      "  Using cached thinc-8.1.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (910 kB)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/maxwell/anaconda3/lib/python3.10/site-packages (from spacy<4.0.0,>=3.5.0->pysentimiento) (5.2.1)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: setuptools in /home/maxwell/anaconda3/lib/python3.10/site-packages (from spacy<4.0.0,>=3.5.0->pysentimiento) (65.6.3)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Requirement already satisfied: typing-extensions in /home/maxwell/anaconda3/lib/python3.10/site-packages (from torch<2.0.0,>=1.13.1->pysentimiento) (4.4.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Requirement already satisfied: wheel in /home/maxwell/anaconda3/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.0.0,>=1.13.1->pysentimiento) (0.38.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/maxwell/anaconda3/lib/python3.10/site-packages (from transformers>=4.13.0->pysentimiento) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/maxwell/anaconda3/lib/python3.10/site-packages (from transformers>=4.13.0->pysentimiento) (2022.7.9)\n",
      "Requirement already satisfied: filelock in /home/maxwell/anaconda3/lib/python3.10/site-packages (from transformers>=4.13.0->pysentimiento) (3.9.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/maxwell/anaconda3/lib/python3.10/site-packages (from transformers>=4.13.0->pysentimiento) (0.11.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/maxwell/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=1.13.3->pysentimiento) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/maxwell/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=1.13.3->pysentimiento) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/maxwell/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=1.13.3->pysentimiento) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/maxwell/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=1.13.3->pysentimiento) (2.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/maxwell/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=1.13.3->pysentimiento) (22.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/maxwell/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=1.13.3->pysentimiento) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/maxwell/anaconda3/lib/python3.10/site-packages (from aiohttp->datasets>=1.13.3->pysentimiento) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/maxwell/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=1.13.3->pysentimiento) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/maxwell/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=1.13.3->pysentimiento) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/maxwell/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=1.13.3->pysentimiento) (2022.12.7)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Using cached blis-0.7.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Using cached confection-0.0.4-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/maxwell/anaconda3/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy<4.0.0,>=3.5.0->pysentimiento) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/maxwell/anaconda3/lib/python3.10/site-packages (from jinja2->spacy<4.0.0,>=3.5.0->pysentimiento) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/maxwell/anaconda3/lib/python3.10/site-packages (from pandas->datasets>=1.13.3->pysentimiento) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/maxwell/anaconda3/lib/python3.10/site-packages (from pandas->datasets>=1.13.3->pysentimiento) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /home/maxwell/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets>=1.13.3->pysentimiento) (1.16.0)\n",
      "Building wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171032 sha256=5622c0532c1d9e7d5e919bdaaf5e929342edc6987cd9d7cc76f196e178071ad9\n",
      "  Stored in directory: /home/maxwell/.cache/pip/wheels/37/b1/70/d87e2dddea71a019314970e3ea065b63e27b9be29e4a579b13\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji, cymem, wasabi, typer, spacy-loggers, spacy-legacy, pydantic, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, murmurhash, langcodes, catalogue, blis, srsly, preshed, pathy, nvidia-cudnn-cu11, torch, confection, thinc, spacy, pysentimiento\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.1\n",
      "    Uninstalling torch-1.12.1:\n",
      "      Successfully uninstalled torch-1.12.1\n",
      "Successfully installed blis-0.7.9 catalogue-2.0.8 confection-0.0.4 cymem-2.0.7 emoji-1.7.0 langcodes-3.3.0 murmurhash-1.0.9 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 pathy-0.10.1 preshed-3.0.8 pydantic-1.10.7 pysentimiento-0.6.7 spacy-3.5.2 spacy-legacy-3.0.12 spacy-loggers-1.0.4 srsly-2.4.6 thinc-8.1.9 torch-1.13.1 typer-0.7.0 wasabi-1.1.1\n",
      "Requirement already satisfied: scikit-learn in /home/maxwell/anaconda3/lib/python3.10/site-packages (1.2.1)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib>=1.1.1 in /home/maxwell/anaconda3/lib/python3.10/site-packages (from scikit-learn) (1.1.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/maxwell/anaconda3/lib/python3.10/site-packages (from scikit-learn) (1.10.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/maxwell/anaconda3/lib/python3.10/site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/maxwell/anaconda3/lib/python3.10/site-packages (from scikit-learn) (2.2.0)\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.2.1\n",
      "    Uninstalling scikit-learn-1.2.1:\n",
      "      Successfully uninstalled scikit-learn-1.2.1\n",
      "Successfully installed scikit-learn-1.2.2\n"
     ]
    }
   ],
   "source": [
    "# !python3 -m venv venv_pysentimiento\n",
    "!pip install pysentimiento\n",
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysentimiento import create_analyzer\n",
    "sentiment_analyzer = create_analyzer(task=\"sentiment\", lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Sentiment_Dataset/SemEval17/Augmented/augmented_SemEval17.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['predicted_polarity'] = np.nan\n",
    "data['augmented_polarity'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>polarity</th>\n",
       "      <th>text</th>\n",
       "      <th>augmented</th>\n",
       "      <th>predicted_polarity</th>\n",
       "      <th>augmented_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NEU</td>\n",
       "      <td>Picturehouse's, Pink Floyd's, 'Roger Waters: T...</td>\n",
       "      <td>Picturehouse's,, 'Roger: The - opening 29 Sept...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NEU</td>\n",
       "      <td>Order Go Set a Watchman in store or through ou...</td>\n",
       "      <td>tell proceed countersink a watchman in stock o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NEG</td>\n",
       "      <td>If these runway renovations at the airport pre...</td>\n",
       "      <td>If these rails restoration at the aerodrome fo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NEU</td>\n",
       "      <td>If you could ask an onstage interview question...</td>\n",
       "      <td>If ask an onstage Miss USA tomorrow, it?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>POS</td>\n",
       "      <td>A portion of book sales from our Harper Lee/Go...</td>\n",
       "      <td>ampere dowry of Koran sales from our Harper le...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20627</th>\n",
       "      <td>20627</td>\n",
       "      <td>NEU</td>\n",
       "      <td>@ShaquilleHoNeal from what I think you're aski...</td>\n",
       "      <td>@asking what from in Future no ShaquilleHoNeal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20628</th>\n",
       "      <td>20628</td>\n",
       "      <td>POS</td>\n",
       "      <td>Iran ranks 1st in liver surgeries, Allah bless...</td>\n",
       "      <td>Iran outrank ranks 1st first in liver surgerie...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20629</th>\n",
       "      <td>20629</td>\n",
       "      <td>NEU</td>\n",
       "      <td>Hours before he arrived in Saudi Arabia on Tue...</td>\n",
       "      <td>Hours Tuesday he Arabia mercilessly Syria's in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20630</th>\n",
       "      <td>20630</td>\n",
       "      <td>NEG</td>\n",
       "      <td>@VanityFair  Alex Kim Kardashian worth how to ...</td>\n",
       "      <td>@VanityFair  Alex Kim Kardashian Worth how to ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20631</th>\n",
       "      <td>20631</td>\n",
       "      <td>NEU</td>\n",
       "      <td>I guess even Pandora knows Justin Bieber is a ...</td>\n",
       "      <td>ace estimate still Pandora recognize Justin Bi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20632 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0 polarity                                               text  \\\n",
       "0               0      NEU  Picturehouse's, Pink Floyd's, 'Roger Waters: T...   \n",
       "1               1      NEU  Order Go Set a Watchman in store or through ou...   \n",
       "2               2      NEG  If these runway renovations at the airport pre...   \n",
       "3               3      NEU  If you could ask an onstage interview question...   \n",
       "4               4      POS  A portion of book sales from our Harper Lee/Go...   \n",
       "...           ...      ...                                                ...   \n",
       "20627       20627      NEU  @ShaquilleHoNeal from what I think you're aski...   \n",
       "20628       20628      POS  Iran ranks 1st in liver surgeries, Allah bless...   \n",
       "20629       20629      NEU  Hours before he arrived in Saudi Arabia on Tue...   \n",
       "20630       20630      NEG  @VanityFair  Alex Kim Kardashian worth how to ...   \n",
       "20631       20631      NEU  I guess even Pandora knows Justin Bieber is a ...   \n",
       "\n",
       "                                               augmented  predicted_polarity  \\\n",
       "0      Picturehouse's,, 'Roger: The - opening 29 Sept...                 NaN   \n",
       "1      tell proceed countersink a watchman in stock o...                 NaN   \n",
       "2      If these rails restoration at the aerodrome fo...                 NaN   \n",
       "3               If ask an onstage Miss USA tomorrow, it?                 NaN   \n",
       "4      ampere dowry of Koran sales from our Harper le...                 NaN   \n",
       "...                                                  ...                 ...   \n",
       "20627  @asking what from in Future no ShaquilleHoNeal...                 NaN   \n",
       "20628  Iran outrank ranks 1st first in liver surgerie...                 NaN   \n",
       "20629  Hours Tuesday he Arabia mercilessly Syria's in...                 NaN   \n",
       "20630  @VanityFair  Alex Kim Kardashian Worth how to ...                 NaN   \n",
       "20631  ace estimate still Pandora recognize Justin Bi...                 NaN   \n",
       "\n",
       "       augmented_polarity  \n",
       "0                     NaN  \n",
       "1                     NaN  \n",
       "2                     NaN  \n",
       "3                     NaN  \n",
       "4                     NaN  \n",
       "...                   ...  \n",
       "20627                 NaN  \n",
       "20628                 NaN  \n",
       "20629                 NaN  \n",
       "20630                 NaN  \n",
       "20631                 NaN  \n",
       "\n",
       "[20632 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20632 [00:00<?, ?it/s]/tmp/ipykernel_36943/1327365210.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['predicted_polarity'][i] = sentiment_analyzer.predict(data['text'][i]).output\n",
      "/tmp/ipykernel_36943/1327365210.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['augmented_polarity'][i] = sentiment_analyzer.predict(data['augmented'][i]).output\n",
      " 13%|█▎        | 2728/20632 [03:03<20:05, 14.86it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(data))):\n\u001b[0;32m----> 3\u001b[0m     data[\u001b[39m'\u001b[39m\u001b[39mpredicted_polarity\u001b[39m\u001b[39m'\u001b[39m][i] \u001b[39m=\u001b[39m sentiment_analyzer\u001b[39m.\u001b[39;49mpredict(data[\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m][i])\u001b[39m.\u001b[39moutput\n\u001b[1;32m      4\u001b[0m     data[\u001b[39m'\u001b[39m\u001b[39maugmented_polarity\u001b[39m\u001b[39m'\u001b[39m][i] \u001b[39m=\u001b[39m sentiment_analyzer\u001b[39m.\u001b[39mpredict(data[\u001b[39m'\u001b[39m\u001b[39maugmented\u001b[39m\u001b[39m'\u001b[39m][i])\u001b[39m.\u001b[39moutput\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pysentimiento/analyzer.py:298\u001b[0m, in \u001b[0;36mAnalyzerForSequenceClassification.predict\u001b[0;34m(self, inputs, context, target, preprocess_context)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[39mif\u001b[39;00m context \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(context, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    297\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mContext must be a string\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 298\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict_single(inputs, context\u001b[39m=\u001b[39;49mcontext, preprocess_context\u001b[39m=\u001b[39;49mpreprocess_context)\n\u001b[1;32m    299\u001b[0m \u001b[39melif\u001b[39;00m context \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(context, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    300\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mContext must be a list of strings\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pysentimiento/analyzer.py:265\u001b[0m, in \u001b[0;36mAnalyzerForSequenceClassification._predict_single\u001b[0;34m(self, sentence, context, preprocess_context)\u001b[0m\n\u001b[1;32m    257\u001b[0m     inputs\u001b[39m.\u001b[39mappend(context)\n\u001b[1;32m    258\u001b[0m idx \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mLongTensor(\n\u001b[1;32m    259\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mencode(\n\u001b[1;32m    260\u001b[0m         \u001b[39m*\u001b[39minputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m     )\n\u001b[1;32m    264\u001b[0m )\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m--> 265\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(idx)\n\u001b[1;32m    266\u001b[0m logits \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mlogits\n\u001b[1;32m    267\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_output(sentence, logits)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1122\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mregister_forward_pre_hook\u001b[39m(\u001b[39mself\u001b[39m, hook: Callable[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39mNone\u001b[39;00m]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m RemovableHandle:\n\u001b[1;32m   1123\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Registers a forward pre-hook on the module.\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \n\u001b[1;32m   1125\u001b[0m \u001b[39m    The hook will be called every time before :func:`forward` is invoked.\u001b[39;00m\n\u001b[1;32m   1126\u001b[0m \u001b[39m    It should have the following signature::\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \n\u001b[1;32m   1128\u001b[0m \u001b[39m        hook(module, input) -> None or modified input\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \n\u001b[0;32m-> 1130\u001b[0m \u001b[39m    The input contains only the positional arguments given to the module.\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \u001b[39m    Keyword arguments won't be passed to the hooks and only to the ``forward``.\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m \u001b[39m    The hook can modify the input. User can either return a tuple or a\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m \u001b[39m    single modified value in the hook. We will wrap the value into a tuple\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m \u001b[39m    if a single value is returned(unless that value is already a tuple).\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \n\u001b[1;32m   1136\u001b[0m \u001b[39m    Returns:\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[39m        :class:`torch.utils.hooks.RemovableHandle`:\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[39m            a handle that can be used to remove the added hook by calling\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[39m            ``handle.remove()``\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1141\u001b[0m     handle \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mRemovableHandle(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks)\n\u001b[1;32m   1142\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks[handle\u001b[39m.\u001b[39mid] \u001b[39m=\u001b[39m hook\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:1208\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1200\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1201\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1202\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1203\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1205\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1206\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1208\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroberta(\n\u001b[1;32m   1209\u001b[0m     input_ids,\n\u001b[1;32m   1210\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1211\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1212\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1213\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1214\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1215\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1216\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1217\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1218\u001b[0m )\n\u001b[1;32m   1219\u001b[0m sequence_output \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1220\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1122\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mregister_forward_pre_hook\u001b[39m(\u001b[39mself\u001b[39m, hook: Callable[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39mNone\u001b[39;00m]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m RemovableHandle:\n\u001b[1;32m   1123\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Registers a forward pre-hook on the module.\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \n\u001b[1;32m   1125\u001b[0m \u001b[39m    The hook will be called every time before :func:`forward` is invoked.\u001b[39;00m\n\u001b[1;32m   1126\u001b[0m \u001b[39m    It should have the following signature::\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \n\u001b[1;32m   1128\u001b[0m \u001b[39m        hook(module, input) -> None or modified input\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \n\u001b[0;32m-> 1130\u001b[0m \u001b[39m    The input contains only the positional arguments given to the module.\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \u001b[39m    Keyword arguments won't be passed to the hooks and only to the ``forward``.\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m \u001b[39m    The hook can modify the input. User can either return a tuple or a\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m \u001b[39m    single modified value in the hook. We will wrap the value into a tuple\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m \u001b[39m    if a single value is returned(unless that value is already a tuple).\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \n\u001b[1;32m   1136\u001b[0m \u001b[39m    Returns:\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[39m        :class:`torch.utils.hooks.RemovableHandle`:\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[39m            a handle that can be used to remove the added hook by calling\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[39m            ``handle.remove()``\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1141\u001b[0m     handle \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mRemovableHandle(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks)\n\u001b[1;32m   1142\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks[handle\u001b[39m.\u001b[39mid] \u001b[39m=\u001b[39m hook\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:846\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    837\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    839\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m    840\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m    841\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    844\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    845\u001b[0m )\n\u001b[0;32m--> 846\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m    847\u001b[0m     embedding_output,\n\u001b[1;32m    848\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m    849\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    850\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    851\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m    852\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    853\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    854\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    855\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    856\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    857\u001b[0m )\n\u001b[1;32m    858\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    859\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1122\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mregister_forward_pre_hook\u001b[39m(\u001b[39mself\u001b[39m, hook: Callable[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39mNone\u001b[39;00m]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m RemovableHandle:\n\u001b[1;32m   1123\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Registers a forward pre-hook on the module.\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \n\u001b[1;32m   1125\u001b[0m \u001b[39m    The hook will be called every time before :func:`forward` is invoked.\u001b[39;00m\n\u001b[1;32m   1126\u001b[0m \u001b[39m    It should have the following signature::\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \n\u001b[1;32m   1128\u001b[0m \u001b[39m        hook(module, input) -> None or modified input\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \n\u001b[0;32m-> 1130\u001b[0m \u001b[39m    The input contains only the positional arguments given to the module.\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \u001b[39m    Keyword arguments won't be passed to the hooks and only to the ``forward``.\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m \u001b[39m    The hook can modify the input. User can either return a tuple or a\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m \u001b[39m    single modified value in the hook. We will wrap the value into a tuple\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m \u001b[39m    if a single value is returned(unless that value is already a tuple).\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \n\u001b[1;32m   1136\u001b[0m \u001b[39m    Returns:\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[39m        :class:`torch.utils.hooks.RemovableHandle`:\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[39m            a handle that can be used to remove the added hook by calling\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[39m            ``handle.remove()``\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1141\u001b[0m     handle \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mRemovableHandle(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks)\n\u001b[1;32m   1142\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks[handle\u001b[39m.\u001b[39mid] \u001b[39m=\u001b[39m hook\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:520\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    511\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    512\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    513\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    517\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    518\u001b[0m     )\n\u001b[1;32m    519\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 520\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    521\u001b[0m         hidden_states,\n\u001b[1;32m    522\u001b[0m         attention_mask,\n\u001b[1;32m    523\u001b[0m         layer_head_mask,\n\u001b[1;32m    524\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    525\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    526\u001b[0m         past_key_value,\n\u001b[1;32m    527\u001b[0m         output_attentions,\n\u001b[1;32m    528\u001b[0m     )\n\u001b[1;32m    530\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    531\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1122\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mregister_forward_pre_hook\u001b[39m(\u001b[39mself\u001b[39m, hook: Callable[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39mNone\u001b[39;00m]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m RemovableHandle:\n\u001b[1;32m   1123\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Registers a forward pre-hook on the module.\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \n\u001b[1;32m   1125\u001b[0m \u001b[39m    The hook will be called every time before :func:`forward` is invoked.\u001b[39;00m\n\u001b[1;32m   1126\u001b[0m \u001b[39m    It should have the following signature::\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \n\u001b[1;32m   1128\u001b[0m \u001b[39m        hook(module, input) -> None or modified input\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \n\u001b[0;32m-> 1130\u001b[0m \u001b[39m    The input contains only the positional arguments given to the module.\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \u001b[39m    Keyword arguments won't be passed to the hooks and only to the ``forward``.\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m \u001b[39m    The hook can modify the input. User can either return a tuple or a\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m \u001b[39m    single modified value in the hook. We will wrap the value into a tuple\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m \u001b[39m    if a single value is returned(unless that value is already a tuple).\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \n\u001b[1;32m   1136\u001b[0m \u001b[39m    Returns:\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[39m        :class:`torch.utils.hooks.RemovableHandle`:\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[39m            a handle that can be used to remove the added hook by calling\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[39m            ``handle.remove()``\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1141\u001b[0m     handle \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mRemovableHandle(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks)\n\u001b[1;32m   1142\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks[handle\u001b[39m.\u001b[39mid] \u001b[39m=\u001b[39m hook\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:447\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    444\u001b[0m     cross_attn_present_key_value \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    445\u001b[0m     present_key_value \u001b[39m=\u001b[39m present_key_value \u001b[39m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 447\u001b[0m layer_output \u001b[39m=\u001b[39m apply_chunking_to_forward(\n\u001b[1;32m    448\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_forward_chunk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_size_feed_forward, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_len_dim, attention_output\n\u001b[1;32m    449\u001b[0m )\n\u001b[1;32m    450\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs\n\u001b[1;32m    452\u001b[0m \u001b[39m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/pytorch_utils.py:246\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[39m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(output_chunks, dim\u001b[39m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 246\u001b[0m \u001b[39mreturn\u001b[39;00m forward_fn(\u001b[39m*\u001b[39;49minput_tensors)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:459\u001b[0m, in \u001b[0;36mRobertaLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed_forward_chunk\u001b[39m(\u001b[39mself\u001b[39m, attention_output):\n\u001b[0;32m--> 459\u001b[0m     intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintermediate(attention_output)\n\u001b[1;32m    460\u001b[0m     layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    461\u001b[0m     \u001b[39mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1122\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mregister_forward_pre_hook\u001b[39m(\u001b[39mself\u001b[39m, hook: Callable[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39mNone\u001b[39;00m]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m RemovableHandle:\n\u001b[1;32m   1123\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Registers a forward pre-hook on the module.\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \n\u001b[1;32m   1125\u001b[0m \u001b[39m    The hook will be called every time before :func:`forward` is invoked.\u001b[39;00m\n\u001b[1;32m   1126\u001b[0m \u001b[39m    It should have the following signature::\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \n\u001b[1;32m   1128\u001b[0m \u001b[39m        hook(module, input) -> None or modified input\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \n\u001b[0;32m-> 1130\u001b[0m \u001b[39m    The input contains only the positional arguments given to the module.\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \u001b[39m    Keyword arguments won't be passed to the hooks and only to the ``forward``.\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m \u001b[39m    The hook can modify the input. User can either return a tuple or a\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m \u001b[39m    single modified value in the hook. We will wrap the value into a tuple\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m \u001b[39m    if a single value is returned(unless that value is already a tuple).\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \n\u001b[1;32m   1136\u001b[0m \u001b[39m    Returns:\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[39m        :class:`torch.utils.hooks.RemovableHandle`:\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[39m            a handle that can be used to remove the added hook by calling\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[39m            ``handle.remove()``\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1141\u001b[0m     handle \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mRemovableHandle(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks)\n\u001b[1;32m   1142\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks[handle\u001b[39m.\u001b[39mid] \u001b[39m=\u001b[39m hook\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:357\u001b[0m, in \u001b[0;36mRobertaIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m--> 357\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdense(hidden_states)\n\u001b[1;32m    358\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[1;32m    359\u001b[0m     \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1122\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mregister_forward_pre_hook\u001b[39m(\u001b[39mself\u001b[39m, hook: Callable[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39mNone\u001b[39;00m]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m RemovableHandle:\n\u001b[1;32m   1123\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Registers a forward pre-hook on the module.\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \n\u001b[1;32m   1125\u001b[0m \u001b[39m    The hook will be called every time before :func:`forward` is invoked.\u001b[39;00m\n\u001b[1;32m   1126\u001b[0m \u001b[39m    It should have the following signature::\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \n\u001b[1;32m   1128\u001b[0m \u001b[39m        hook(module, input) -> None or modified input\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \n\u001b[0;32m-> 1130\u001b[0m \u001b[39m    The input contains only the positional arguments given to the module.\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \u001b[39m    Keyword arguments won't be passed to the hooks and only to the ``forward``.\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m \u001b[39m    The hook can modify the input. User can either return a tuple or a\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m \u001b[39m    single modified value in the hook. We will wrap the value into a tuple\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m \u001b[39m    if a single value is returned(unless that value is already a tuple).\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \n\u001b[1;32m   1136\u001b[0m \u001b[39m    Returns:\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[39m        :class:`torch.utils.hooks.RemovableHandle`:\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[39m            a handle that can be used to remove the added hook by calling\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[39m            ``handle.remove()``\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1141\u001b[0m     handle \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mRemovableHandle(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks)\n\u001b[1;32m   1142\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks[handle\u001b[39m.\u001b[39mid] \u001b[39m=\u001b[39m hook\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(data))):\n",
    "\n",
    "    data['predicted_polarity'][i] = sentiment_analyzer.predict(data['text'][i]).output\n",
    "    data['augmented_polarity'][i] = sentiment_analyzer.predict(data['augmented'][i]).output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('./Sentiment_Dataset/Sentiment140/Augmented/predicted_sentiment140.csv', encoding='utf-8',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['polarity'].replace(0,'NEG', inplace=True)\n",
    "data['polarity'].replace(2,'NEU', inplace=True)\n",
    "data['polarity'].replace(4,'POS', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet</th>\n",
       "      <th>augmented</th>\n",
       "      <th>predicted_polarity</th>\n",
       "      <th>augmented_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NEG</td>\n",
       "      <td>VERY SAD! MY BROTHER GOES BACK TO GERMANY TOMO...</td>\n",
       "      <td>VERY MY! SAD BACK GOES BROTHER TO GERMANY TOMO...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NEG</td>\n",
       "      <td>Really sad I can't participate at the bike wee...</td>\n",
       "      <td>Really sad really I can't HTTP participate wor...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>POS</td>\n",
       "      <td>@iamabhimanyu thanks</td>\n",
       "      <td>@iamabhimanyu thank</td>\n",
       "      <td>POS</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>POS</td>\n",
       "      <td>mando diao LIVE @rock am ring 09 so toll und d...</td>\n",
       "      <td>mando diao LIVE @Rock rock am ring MA 09 caree...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NEG</td>\n",
       "      <td>@n8lewis I wish that I could have helped</td>\n",
       "      <td>@n8lewis that I wish could I have helped</td>\n",
       "      <td>POS</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>49995</td>\n",
       "      <td>NEG</td>\n",
       "      <td>@astrid_sunrise Aw. I've been trying to convin...</td>\n",
       "      <td>@astrid_sunrise Aw. I've been examine to conve...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>49996</td>\n",
       "      <td>NEG</td>\n",
       "      <td>first admu-dlsu game on aug. 9 :| i have class...</td>\n",
       "      <td>maiden admu-dlsu gamey on aug. IX :| i have cl...</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>49997</td>\n",
       "      <td>POS</td>\n",
       "      <td>why must wake up so early. I need my sleeeeep....</td>\n",
       "      <td>why I so up wake shelby. must need my sleeeeep...</td>\n",
       "      <td>NEG</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>49998</td>\n",
       "      <td>POS</td>\n",
       "      <td>Quiiierooo ver Up y Star Treck</td>\n",
       "      <td>Quiiierooo 5 astir y principal Treck</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>49999</td>\n",
       "      <td>NEG</td>\n",
       "      <td>Getting my car fixed. I have to leave it overn...</td>\n",
       "      <td>car fixed. have it overnight</td>\n",
       "      <td>NEU</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0 polarity                                              tweet  \\\n",
       "0               0      NEG  VERY SAD! MY BROTHER GOES BACK TO GERMANY TOMO...   \n",
       "1               1      NEG  Really sad I can't participate at the bike wee...   \n",
       "2               2      POS                              @iamabhimanyu thanks    \n",
       "3               3      POS  mando diao LIVE @rock am ring 09 so toll und d...   \n",
       "4               4      NEG          @n8lewis I wish that I could have helped    \n",
       "...           ...      ...                                                ...   \n",
       "49995       49995      NEG  @astrid_sunrise Aw. I've been trying to convin...   \n",
       "49996       49996      NEG  first admu-dlsu game on aug. 9 :| i have class...   \n",
       "49997       49997      POS  why must wake up so early. I need my sleeeeep....   \n",
       "49998       49998      POS                    Quiiierooo ver Up y Star Treck    \n",
       "49999       49999      NEG  Getting my car fixed. I have to leave it overn...   \n",
       "\n",
       "                                               augmented predicted_polarity  \\\n",
       "0      VERY MY! SAD BACK GOES BROTHER TO GERMANY TOMO...                NEG   \n",
       "1      Really sad really I can't HTTP participate wor...                NEG   \n",
       "2                                   @iamabhimanyu thank                 POS   \n",
       "3      mando diao LIVE @Rock rock am ring MA 09 caree...                NEU   \n",
       "4              @n8lewis that I wish could I have helped                 POS   \n",
       "...                                                  ...                ...   \n",
       "49995  @astrid_sunrise Aw. I've been examine to conve...                NEG   \n",
       "49996  maiden admu-dlsu gamey on aug. IX :| i have cl...                NEU   \n",
       "49997  why I so up wake shelby. must need my sleeeeep...                NEG   \n",
       "49998              Quiiierooo 5 astir y principal Treck                 NEU   \n",
       "49999                      car fixed. have it overnight                 NEU   \n",
       "\n",
       "      augmented_polarity  \n",
       "0                    NEG  \n",
       "1                    NEG  \n",
       "2                    NEU  \n",
       "3                    NEU  \n",
       "4                    NEU  \n",
       "...                  ...  \n",
       "49995                NEU  \n",
       "49996                NEU  \n",
       "49997                NEU  \n",
       "49998                NEU  \n",
       "49999                NEU  \n",
       "\n",
       "[50000 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxwell/Thesis/restructure/venv_pysentimiento/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/maxwell/Thesis/restructure/venv_pysentimiento/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/maxwell/Thesis/restructure/venv_pysentimiento/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.88      0.55      0.68     25092\n",
      "         NEU       0.00      0.00      0.00         0\n",
      "         POS       0.78      0.62      0.69     24908\n",
      "\n",
      "    accuracy                           0.58     50000\n",
      "   macro avg       0.55      0.39      0.46     50000\n",
      "weighted avg       0.83      0.58      0.68     50000\n",
      "\n",
      "CONFUSSION MATRIX\n",
      "[[13751  6959  4382]\n",
      " [    0     0     0]\n",
      " [ 1851  7657 15400]]\n"
     ]
    }
   ],
   "source": [
    "print(\"REPORT\")\n",
    "print(classification_report(data['polarity'], data[\"predicted_polarity\"], target_names=['NEG','NEU','POS']))\n",
    "\n",
    "print(\"CONFUSSION MATRIX\")\n",
    "print(confusion_matrix(data['polarity'], data[\"predicted_polarity\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxwell/Thesis/restructure/venv_pysentimiento/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/maxwell/Thesis/restructure/venv_pysentimiento/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/maxwell/Thesis/restructure/venv_pysentimiento/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.84      0.41      0.56     25092\n",
      "         NEU       0.00      0.00      0.00         0\n",
      "         POS       0.76      0.45      0.57     24908\n",
      "\n",
      "    accuracy                           0.43     50000\n",
      "   macro avg       0.53      0.29      0.37     50000\n",
      "weighted avg       0.80      0.43      0.56     50000\n",
      "\n",
      "CONFUSSION MATRIX\n",
      "[[10408 11216  3468]\n",
      " [    0     0     0]\n",
      " [ 1977 11701 11230]]\n"
     ]
    }
   ],
   "source": [
    "print(\"REPORT\")\n",
    "print(classification_report(data['polarity'], data[\"augmented_polarity\"], target_names=['NEG','NEU','POS']))\n",
    "\n",
    "print(\"CONFUSSION MATRIX\")\n",
    "print(confusion_matrix(data['polarity'], data[\"augmented_polarity\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NEG', 'POS'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(data['polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_txtatck",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
